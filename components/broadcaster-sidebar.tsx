"use client";

import { useState, useRef, useEffect, useCallback } from "react";
import { Radio, Mic, Monitor, Globe } from "lucide-react";
import { supabase } from "@/lib/supabaseClient";
import { cn } from "@/lib/utils";
import { useGeminiLiveTranscription } from "@/hooks/use-gemini-live-transcription";

interface BroadcasterSidebarProps {
  onActiveChange?: (isActive: boolean) => void;
}

const ALL_LANGUAGES = [
  { code: "", label: "âœ¨ Auto-detect (System Default)" },
  { code: "en-US", label: "English (United States)" },
  { code: "en-GB", label: "English (United Kingdom)" },
  { code: "es-ES", label: "Spanish (Spain)" },
  { code: "es-MX", label: "Spanish (Mexico)" },
  { code: "fr-FR", label: "French (France)" },
  { code: "de-DE", label: "German (Germany)" },
  { code: "it-IT", label: "Italian (Italy)" },
  { code: "pt-BR", label: "Portuguese (Brazil)" },
  { code: "zh-CN", label: "Chinese, Mandarin (Simplified)" },
  { code: "ja-JP", label: "Japanese (Japan)" },
  { code: "ko-KR", label: "Korean (South Korea)" },
  { code: "tl-PH", label: "Tagalog (Philippines)" },
];

function getClientId(): string {
  if (typeof window === "undefined") return "";
  
  const key = "eburon_anon_client_id";
  let id = localStorage.getItem(key);
  if (!id) {
    id = crypto.randomUUID?.() || `client-${Math.random().toString(36).slice(2)}`;
    localStorage.setItem(key, id);
  }
  return id;
}

export function BroadcasterSidebar({ onActiveChange }: BroadcasterSidebarProps) {
  const [isActive, setIsActive] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [lastSaved, setLastSaved] = useState("");
  const [sourceLang, setSourceLang] = useState("");
  const [audioSource, setAudioSource] = useState<"mic" | "screen">("mic");
  const [statusMessage, setStatusMessage] = useState("Idle");

  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationFrameRef = useRef<number>(null);
  const recognitionRef = useRef<any>(null);
  const saveIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const analyzerRef = useRef<AnalyserNode | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  
  // Track current session for DB
  const currentSessionId = useRef<string>("");
  const currentRecordId = useRef<string>("");

  // Audio visualizer
  const startVisualizer = useCallback(async (stream?: MediaStream) => {
    try {
      const audioStream = stream || await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const sourceNode = audioContext.createMediaStreamSource(audioStream);
      const analyzer = audioContext.createAnalyser();
      analyzer.fftSize = 256;
      sourceNode.connect(analyzer);

      audioContextRef.current = audioContext;
      analyzerRef.current = analyzer;

      const canvas = canvasRef.current;
      if (!canvas) return;
      const ctx = canvas.getContext("2d");
      if (!ctx) return;

      const bufferLength = analyzer.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      const draw = () => {
        animationFrameRef.current = requestAnimationFrame(draw);
        analyzer.getByteFrequencyData(dataArray);

        ctx.fillStyle = "#0b0f18";
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        const barWidth = (canvas.width / bufferLength) * 2.5;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          const barHeight = dataArray[i] / 2;
          const gradient = ctx.createLinearGradient(0, canvas.height - barHeight, 0, canvas.height);
          gradient.addColorStop(0, "#00e0ff");
          gradient.addColorStop(1, "#006dff");
          ctx.fillStyle = gradient;
          ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
          x += barWidth + 1;
        }
      };

      draw();
    } catch (err) {
      console.error("Visualizer error:", err);
    }
  }, []);

  const stopVisualizer = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
    }
  }, []);

  // Gemini Live Transcription Hook
  const { 
    startTranscription: startGemini, 
    stopTranscription: stopGemini, 
    transcript: geminiTranscript,
    isConnected,
    error: geminiError 
  } = useGeminiLiveTranscription({
    sessionId: currentSessionId.current || `session-${Date.now()}`,
    userId: getClientId()
  });

  // Sync Gemini transcript to local state
  useEffect(() => {
    if (geminiTranscript) {
      setTranscript(geminiTranscript);
    }
  }, [geminiTranscript]);

  // Error handling
  useEffect(() => {
    if (geminiError) {
      setStatusMessage(`Error: ${geminiError}`);
      setIsActive(false);
    }
  }, [geminiError]);

  // Note: Web Speech API logic removed in favor of Server-Side Gemini
  
  // Supabase auto-save every 5 seconds (Still relevant if we want client-side backup, 
  // BUT Server is now also saving. To avoid duplicates, we might want to disable client save 
  // OR rely solely on server. User asked for "reliable saving" and we implemented server saving.
  // HOWEVER, the UI expects 'transcript' state to update.
  // We will keep the UI update but DISABLE client-side saving to avoid double-writes 
  // if the server is doing it.
  // But wait, server might fail? Let's rely on server for "saving" as per recent tasks.
  // I will comment out client-side saving to prevent conflicts, or keep it as "local backup" if needed.
  // User said "nothing was saved", so they rely on THIS logic? 
  // NO, they asked to refactor server to use tools for saving. So Server is primary.
  // I'll leave the auto-save commented out or removed to avoid conflict.
  
  /* 
  Client-side auto-save disabled in favor of Server-Side Tool Saving 
  to prevent Race Conditions and Duplicates.
  */

  // Toggle broadcaster
  const toggleBroadcaster = useCallback(async () => {
    if (isActive) {
      // Stop
      stopGemini();
      stopVisualizer();
      // stopAutoSave(); // Disabled client side save
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      setIsActive(false);
      setStatusMessage("Stopped");
      onActiveChange?.(false);
      // Reset session IDs
      currentSessionId.current = "";
      currentRecordId.current = "";
    } else {
      // Start
      setTranscript("");
      setLastSaved("");
      
      // Generate new IDs for this session
      currentSessionId.current = crypto.randomUUID?.() || `session-${Date.now()}`;
      currentRecordId.current = crypto.randomUUID?.() || `record-${Date.now()}`;

      let mediaStream = null;

      if (audioSource === "screen") {
        try {
          mediaStream = await navigator.mediaDevices.getDisplayMedia({
            video: true,
            audio: {
                echoCancellation: false,
                noiseSuppression: false,
                autoGainControl: false
            }
          });
        } catch (err) {
          setStatusMessage("Screen share cancelled");
          return;
        }
      } else {
        try {
             mediaStream = await navigator.mediaDevices.getUserMedia({ 
                audio: { 
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                } 
            });
        } catch (err) {
             setStatusMessage("Microphone denied");
             return;
        }
      }
      
      streamRef.current = mediaStream;
      startVisualizer(mediaStream);
      
      // Start Gemini with this stream
      startGemini(mediaStream);
      
      setIsActive(true);
      setStatusMessage("Connecting to Gemini...");
      onActiveChange?.(true);
    }
  }, [isActive, audioSource, stopGemini, stopVisualizer, startVisualizer, startGemini, onActiveChange]);

  // Start auto-save when transcript changes and is active
  useEffect(() => {
    if (isActive && transcript) {
      startAutoSave();
    }
    return () => stopAutoSave();
  }, [isActive, transcript, startAutoSave, stopAutoSave]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      stopTranscription();
      stopVisualizer();
      stopAutoSave();
    };
  }, []);

  return (
    <div className="space-y-5">
      {/* Configuration */}
      <div className="space-y-4">
        <div>
          <label className="text-sm text-white/60 block mb-2">Input Language</label>
          <select
            value={sourceLang}
            onChange={(e) => setSourceLang(e.target.value)}
            disabled={isActive}
            title="Select input language"
            className="w-full bg-dark-3/80 border border-white/10 rounded-apple px-4 py-3 text-white
              focus:outline-none focus:border-[#00e0ff] transition-colors disabled:opacity-50"
          >
            {ALL_LANGUAGES.map((lang) => (
              <option key={lang.code} value={lang.code}>
                {lang.label}
              </option>
            ))}
          </select>
        </div>

        <div>
          <label className="text-sm text-white/60 block mb-2">Audio Source</label>
          <div className="flex gap-3">
            <button
              onClick={() => setAudioSource("mic")}
              disabled={isActive}
              className={cn(
                "flex-1 flex items-center justify-center gap-2 py-3 px-4 rounded-apple border transition-all",
                audioSource === "mic"
                  ? "bg-[#00e0ff]/10 border-[#00e0ff] text-[#00e0ff]"
                  : "bg-dark-3/50 border-white/10 text-white/60 hover:border-white/20"
              )}
            >
              <Mic className="w-4 h-4" />
              <span>Microphone</span>
            </button>
            <button
              onClick={() => setAudioSource("screen")}
              disabled={isActive}
              className={cn(
                "flex-1 flex items-center justify-center gap-2 py-3 px-4 rounded-apple border transition-all",
                audioSource === "screen"
                  ? "bg-[#00e0ff]/10 border-[#00e0ff] text-[#00e0ff]"
                  : "bg-dark-3/50 border-white/10 text-white/60 hover:border-white/20"
              )}
            >
              <Monitor className="w-4 h-4" />
              <span>Screen</span>
            </button>
          </div>
        </div>
      </div>

      {/* Toggle Button */}
      <button
        onClick={toggleBroadcaster}
        className={cn(
          "w-full px-6 py-4 rounded-apple font-semibold text-lg transition-all flex items-center justify-center gap-3 shadow-lg",
          isActive
            ? "bg-red-500 hover:bg-red-600 text-white shadow-red-500/20"
            : "bg-gradient-to-r from-[#00e0ff] to-[#006dff] hover:opacity-90 text-white shadow-blue-500/20"
        )}
      >
        <Radio size={24} className={isActive ? "animate-pulse" : ""} />
        {isActive ? "Stop Broadcasting" : "Start Broadcasting"}
      </button>

      {/* Status */}
      <div className="flex items-center gap-2 text-sm">
        <div className={cn(
          "w-2 h-2 rounded-full",
          isActive ? "bg-green-500 animate-pulse" : "bg-gray-500"
        )} />
        <span className="text-white/60">{statusMessage}</span>
      </div>

      {/* Audio Visualizer */}
      <div className={cn(
        "bg-dark-3/50 rounded-apple p-4 border border-white/10 transition-opacity",
        isActive ? "opacity-100" : "opacity-50"
      )}>
        <canvas
          ref={canvasRef}
          width={500}
          height={60}
          className="w-full h-16 rounded-lg"
        />
      </div>

      {/* Live Transcript */}
      <div className="bg-dark-3/50 rounded-apple p-4 border border-white/10">
        <div className="flex items-center gap-2 mb-3">
          <div className={cn(
            "w-2 h-2 rounded-full",
            isActive ? "bg-green-500 animate-pulse" : "bg-gray-500"
          )} />
          <span className="text-sm font-semibold text-white/80">Live Transcript</span>
          <Globe className="w-4 h-4 text-white/40 ml-auto" />
        </div>
        <div className="min-h-[120px] max-h-[200px] overflow-y-auto bg-black/30 rounded-lg p-3 border border-white/5">
          <p className={cn(
            "text-white/90 text-sm leading-relaxed",
            transcript && "animate-pulse"
          )}>
            {transcript || "Listening..."}
          </p>
        </div>
      </div>

      {/* Info */}
      <div className="text-xs text-white/40 text-center">
        Auto-saving to Supabase every 5 seconds
      </div>
    </div>
  );
}
